{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Import Libraries__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from pprint import pprint \n",
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%run Radar_Clustering_CustomDBScan.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Path Definition__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_to_images = Path(r'C:\\Users\\hussa\\OneDrive\\Desktop\\Projects\\Project\\MOT\\INFRA-3DRC_scene-22\\INFRA-3DRC_scene-22\\camera_01\\camera_01__data')\n",
    "path_to_pcd = Path(r'C:\\Users\\hussa\\OneDrive\\Desktop\\Projects\\Project\\MOT\\INFRA-3DRC_scene-22\\INFRA-3DRC_scene-22\\radar_01\\radar_01__data')\n",
    "\n",
    "scene_image = sorted(list(image for image in path_to_images.iterdir()))\n",
    "scene_pcd = sorted(list(image for image in path_to_pcd.iterdir()))\n",
    "\n",
    "scene_image = scene_image[92:93]\n",
    "scene_pcd = scene_pcd[92:93]\n",
    "\n",
    "yolo_model = YOLO(r\"C:\\Users\\hussa\\OneDrive\\Desktop\\Projects\\Project\\MOT\\best.pt\")\n",
    "\n",
    "calibration_file = Path(r\"C:\\Users\\hussa\\OneDrive\\Desktop\\Projects\\Project\\MOT\\infra_3drc_calibration_with_homography\\calibration__dk_front_night.json\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Function to Process YOLO prediction results__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_box_generator_for_pred(prediction_results):\n",
    "    for result in prediction_results:\n",
    "        cls = result.boxes.cls.cpu().numpy()\n",
    "        conf = result.boxes.conf.cpu().numpy()\n",
    "        detection = result.boxes.xyxy.cpu().numpy()\n",
    "\n",
    "        list_of_pred_boxes = np.column_stack((cls, detection, conf))\n",
    "    \n",
    "    return list_of_pred_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Import Calibration Matrix__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sensor_calibration_dict(calibration_file):\n",
    "    sensor_calibration_dict = {\n",
    "        \"camera_intrinsics\": [],\n",
    "        \"camera_distcoeffs\": [],\n",
    "        \"radar_to_camera\": [],\n",
    "        \"radar_to_lidar\": [],\n",
    "        \"lidar_to_ground\": [],\n",
    "        \"camera_to_ground\": []\n",
    "    }\n",
    "\n",
    "    with open(calibration_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for item in data['calibration']:\n",
    "        if item['calibration'] == 'camera_01':\n",
    "            sensor_calibration_dict['camera_intrinsics'] = item['k']\n",
    "            sensor_calibration_dict['camera_distcoeffs'] = item['D']\n",
    "        elif item['calibration'] == 'radar_01_to_camera_01':\n",
    "            sensor_calibration_dict['radar_to_camera'] = item['T']\n",
    "        elif item['calibration'] == 'radar_01_to_lidar_01':\n",
    "            sensor_calibration_dict['radar_to_lidar'] = item['T']\n",
    "        elif item['calibration'] == 'lidar_01_to_ground':\n",
    "            sensor_calibration_dict['lidar_to_ground'] = item['T']\n",
    "        elif item['calibration'] == 'camera_01_to_ground_homography':\n",
    "            sensor_calibration_dict['camera_to_ground'] = item['T']\n",
    "\n",
    "    return sensor_calibration_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Calibration: Radar to Ground Plane__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radar_to_ground_transfomer(points_array, T, K):\n",
    "\n",
    "    n_p_array = np.array(points_array).reshape(1,-1)\n",
    "    tranposed_array = np.transpose(n_p_array)\n",
    "   \n",
    "    row_of_ones = np.ones((1, 1))           #1x1\n",
    "    stacked_matrix = np.vstack((tranposed_array, row_of_ones))  \n",
    "  \n",
    "    radar_to_lidar_matrix = np.matmul(T, stacked_matrix)             #3x1\n",
    "\n",
    "    new_stacked_matrix = np.vstack((radar_to_lidar_matrix, row_of_ones))             #4x1\n",
    "    in_ground_data = np.matmul(K, new_stacked_matrix)\n",
    "\n",
    "\n",
    "    in_ground = np.transpose(in_ground_data)\n",
    "\n",
    "    return in_ground[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Radar dict: on Ground__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radar_to_ground(radar_dict, sensor_calibration_dict):\n",
    "    def transform_point(point, T, K, is_cluster=False):\n",
    "        updated_centroid = radar_to_ground_transfomer(point[0], T, K)\n",
    "        updated_velocity = point[-1]\n",
    "        \n",
    "        if is_cluster:\n",
    "            updated_lowest_point = radar_to_ground_transfomer(point[1], T, K)\n",
    "            return [updated_centroid, updated_lowest_point, updated_velocity]\n",
    "        return [updated_centroid, updated_velocity]\n",
    "    \n",
    "    T = sensor_calibration_dict['radar_to_lidar']\n",
    "    K = sensor_calibration_dict['lidar_to_ground']\n",
    "\n",
    "    in_ground = {'clusters': [], 'noise': []}\n",
    "\n",
    "    for key, points in radar_dict.items():\n",
    "        is_cluster = key == 'clusters'\n",
    "        for point in points:\n",
    "            if point:\n",
    "                transformed_point = transform_point(point, T, K, is_cluster)\n",
    "                in_ground.setdefault(key, []).append(transformed_point)\n",
    "\n",
    "    return in_ground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Calibration: Radar to Image Plane__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radar_to_camera_transformer(radar_point, T, k):\n",
    "   \n",
    "    n_p_array = np.array(radar_point).reshape(1,-1)\n",
    "    transpose_RPA = np.transpose(n_p_array)\n",
    "\n",
    "    new_array = np.vstack([transpose_RPA, np.ones((1, 1))])             \n",
    "    product_1 = np.matmul(np.array(k), np.array(T))\n",
    "\n",
    "    product_array = np.matmul(product_1, new_array)                      #[su, sv, s] but along column\n",
    "\n",
    "    final_array = product_array / product_array [2]                      #[u, v, 1], along column\n",
    "\n",
    "    u_v = np.delete(final_array, 2, axis = 0)                            #[u, v], along column      \n",
    "    final_u_v = np.transpose(u_v)\n",
    "\n",
    "    return final_u_v[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Radar Dict: on Image__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radar_to_camera(radar_output, sensor_calibration_dict):\n",
    "    def transform_point(point, T, K, is_cluster=False):\n",
    "        updated_centroid = radar_to_camera_transformer(point[0], T, K)\n",
    "        updated_velocity = point[-1]\n",
    "        \n",
    "        if is_cluster:\n",
    "            updated_lowest_point = radar_to_camera_transformer(point[1], T, K)\n",
    "            return [updated_centroid, updated_lowest_point, updated_velocity]\n",
    "        return [updated_centroid, updated_velocity]\n",
    "\n",
    "    T = sensor_calibration_dict['radar_to_camera']\n",
    "    K = sensor_calibration_dict['camera_intrinsics']\n",
    "\n",
    "    in_camera = {'clusters': [], 'noise': []}\n",
    "\n",
    "    for key, points in radar_output.items():\n",
    "        is_cluster = (key == 'clusters')\n",
    "        for point in points:\n",
    "            if point:\n",
    "                transformed_point = transform_point(point, T, K, is_cluster)\n",
    "                in_camera[key].append(transformed_point)\n",
    "\n",
    "    return in_camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Homography: Image to Ground__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homography(points_on_image, sensor_calibration_dict):\n",
    "\n",
    "    points = np.array(points_on_image).reshape(1, -1)\n",
    "\n",
    "    transpose_matrix = np.vstack((np.transpose(points),np.ones((1,1))))\n",
    "    \n",
    "    homogeneous_coordinates = np.matmul(sensor_calibration_dict['camera_to_ground'], transpose_matrix)\n",
    "    ground_coordinates = homogeneous_coordinates / homogeneous_coordinates[-1].reshape(1, -1)\n",
    "\n",
    "    transpose_ground_coordinates = ground_coordinates.T\n",
    "    g_x1y1 = transpose_ground_coordinates[0][:2]\n",
    "\n",
    "    return g_x1y1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Visualization: Camera Points on Ground Plane__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_plotting(image_on_ground, my_plot):\n",
    "    # Colors with cycling support for large number of points\n",
    "    colors = ['blue', 'green', 'orange', 'black', 'purple', 'maroon']\n",
    "    \n",
    "    # Extract and plot coordinates directly\n",
    "    for i, xy in enumerate(image_on_ground):\n",
    "        x_coord = xy[1][0]\n",
    "        y_coord = xy[1][1]\n",
    "\n",
    "        # Cycle through colors if more points than colors\n",
    "        color = colors[i % len(colors)]\n",
    "\n",
    "        # Plot the point\n",
    "        my_plot.scatter(y_coord, x_coord, color=color, label='camera', marker='o')\n",
    "\n",
    "    # Set plot limits and labels\n",
    "    my_plot.set_xlim(-30, 30)\n",
    "    my_plot.set_ylim(0, 100)\n",
    "    my_plot.set_xlabel('Y-axis')\n",
    "    my_plot.set_ylabel('X-axis')\n",
    "    my_plot.set_title('Plot of Points')\n",
    "\n",
    "    # Invert X-axis\n",
    "    my_plot.invert_xaxis()\n",
    "    \n",
    "    return my_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Visualization: Radar points on Ground Plane__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radar_plotting(radar_dict, my_plot):\n",
    "    # Initialize lists for plotting\n",
    "    x_lowest, y_lowest = [], []\n",
    "    x_noise, y_noise = [], []\n",
    "\n",
    "    # Process clusters\n",
    "    for detection in radar_dict['clusters']:\n",
    "        if detection:\n",
    "            lowest_point = detection[1]\n",
    "            x_lowest.append(lowest_point[0])\n",
    "            y_lowest.append(lowest_point[1])\n",
    "    \n",
    "    # Process noise points\n",
    "    for noise in radar_dict['noise']:\n",
    "        if noise:\n",
    "            lowest_point = noise[0]\n",
    "            x_noise.append(lowest_point[0])\n",
    "            y_noise.append(lowest_point[1])\n",
    "\n",
    "    # Plot the points\n",
    "    my_plot.scatter(y_lowest, x_lowest, color='red', label='Lowest Point', marker=\"X\")\n",
    "    my_plot.scatter(y_noise, x_noise, color='grey', label='Noise', marker=\".\")\n",
    "\n",
    "    # Add legend if not already present\n",
    "    if not my_plot.get_legend():\n",
    "        my_plot.legend()\n",
    "\n",
    "    return my_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Expand Bounding Box Dimension__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_bbox(box, scale=1.1):\n",
    "    # Calculate the width and height of the original box\n",
    "    width = box[2] - box[0]     # x2 - x1\n",
    "    height = box[3] - box[1]    # y2 - y1\n",
    "\n",
    "    # Calculate the center of the original box\n",
    "    center_x = box[0] + (width/2)\n",
    "    center_y = box[1] + (height/2)\n",
    "\n",
    "    # Calculate the increase in width and height\n",
    "    new_width = width * scale\n",
    "    new_height = height * scale\n",
    "\n",
    "    # Calculate the new coordinates\n",
    "    new_x1 = 0 if (center_x - new_width / 2) < 0 else (center_x - new_width / 2)\n",
    "    new_y1 = 0 if (center_y - new_height / 2) < 0 else (center_y - new_height / 2)\n",
    "    new_x2 = center_x + new_width / 2\n",
    "    new_y2 = center_y + new_height / 2\n",
    "    \n",
    "    return list([new_x1, new_y1, new_x2, new_y2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Euclidean Distance__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_euclidean_distance(clusters, images):\n",
    "    d = np.sqrt(((clusters[0] - images[0])**2) + ((clusters[1] - images[1])**2))\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Case Filtering__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_association_matrix(list_of_pred_boxes, cluster_on_image, datatype='clusters', association_list=None):\n",
    "\n",
    "    # Select the clusters or noise points based on datatype\n",
    "    clusters = cluster_on_image['clusters'] if datatype == 'clusters' else cluster_on_image['noise']\n",
    "    pred_boxes = list_of_pred_boxes\n",
    "\n",
    "    # Return empty matrix if no clusters or pred_boxes exist\n",
    "    if len(clusters) == 0 or len(pred_boxes) == 0:\n",
    "        return np.zeros((len(clusters), len(pred_boxes)))\n",
    "\n",
    "    # Initialize the association matrix\n",
    "    matrix = np.zeros((len(clusters), len(pred_boxes)))\n",
    "\n",
    "    # Helper function to check if a cluster centroid falls inside a bounding box\n",
    "    def is_centroid_in_bbox(centroid, bbox):\n",
    "        return bbox[0] < centroid[0] < bbox[2] and bbox[1] < centroid[1] < bbox[3]\n",
    "\n",
    "    for pred_idx, prediction in enumerate(pred_boxes):\n",
    "        old_bbox = prediction[1:5]\n",
    "        bbox = expand_bbox(old_bbox, scale=1.2)\n",
    "\n",
    "        for cluster_idx, cluster in enumerate(clusters):\n",
    "            cluster_centroid = cluster[0]\n",
    "            # Determine if we are dealing with clusters or noise\n",
    "            if datatype == 'clusters' or (datatype == 'noise' and pred_idx in association_list['non_associated_bbox']):\n",
    "                matrix[cluster_idx, pred_idx] = int(is_centroid_in_bbox(cluster_centroid, bbox))\n",
    "\n",
    "    return matrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_cases(matrix, datatype='clusters', association_list=None):\n",
    "    \"\"\"\n",
    "    Checks and assigns different cases of radar-image data for spatial association \n",
    "\n",
    "    Examples: \n",
    "    >>> import pprint\n",
    "    >>> matrix = np.array([\n",
    "    ...     [1, 0, 1, 0, 0, 0],\n",
    "    ...     [0, 1, 1, 0, 0, 0],\n",
    "    ...     [1, 1, 0, 0, 0, 0],\n",
    "    ...     [0, 0, 0, 1, 0, 0],\n",
    "    ...     [0, 0, 0, 0, 1, 0],\n",
    "    ...     [0, 0, 0, 0, 1, 0],\n",
    "    ...     [0, 0, 0, 0, 0, 0]\n",
    "    ... ])\n",
    "    >>> pprint.pprint(get_associations(matrix))\n",
    "    {'many_radar_to_many_image': {'cols': [0, 1, 2], 'rows': [0, 1, 2]},\n",
    "     'many_radar_to_one_image': {'cols': [4], 'rows': [(array([4, 5]),)]},\n",
    "     'one_radar_to_many_image': {'cols': [], 'rows': []},\n",
    "     'one_radar_to_one_image': {'cols': [3], 'rows': [3]}}\n",
    "    \"\"\" \n",
    "    associations = {\n",
    "        \"many_cluster_to_many_bbox\" : {\"clusters\": [], \"bbox\": []}, \n",
    "        \"many_cluster_to_one_bbox\"  : {\"clusters\": [], \"bbox\": []},\n",
    "        \"one_cluster_to_many_bbox\"  : {\"clusters\": [], \"bbox\": []}, \n",
    "        \"one_cluster_to_one_bbox\"   : {\"assigned\": []},\n",
    "        \"unassigned_bbox\" : {\"bbox\": []}\n",
    "    }\n",
    "\n",
    "    # MANY TO MANY CHECKS\n",
    "    # -------------------\n",
    "    rows_with_multiple_truths = np.where(np.sum(matrix, axis=1) > 1)[0] \n",
    "    columns_with_multiple_truths = np.where(np.sum(matrix, axis=0) > 1)[0] \n",
    "    # many_too_many = list(set(rows_with_multiple_truths) & set(columns_with_multiple_truths))\n",
    "    # many_radar_to_many_image = [many_too_many, many_too_many]\n",
    "    many_too_many_rows = set() \n",
    "    many_too_many_cols = set() \n",
    "    for r_id in range(matrix.shape[0]):\n",
    "        for c_id in range(matrix.shape[1]):\n",
    "            if r_id in rows_with_multiple_truths and c_id in columns_with_multiple_truths: \n",
    "                if matrix[r_id, c_id] == 1:\n",
    "                     many_too_many_rows.add(r_id)\n",
    "                     many_too_many_cols.add(c_id)\n",
    "\n",
    "    associations['many_cluster_to_many_bbox'][\"clusters\"] = list(many_too_many_rows)\n",
    "    associations['many_cluster_to_many_bbox'][\"bbox\"] = list(many_too_many_cols)\n",
    "\n",
    "    # MANY TO ONE CHECKS \n",
    "    # -------------------\n",
    "    many_to_one = [] \n",
    "    for c in range(matrix.shape[1]): \n",
    "        if c in columns_with_multiple_truths and c not in many_too_many_cols:\n",
    "            associated_rows = np.where(matrix[:, c] > 0)[0]\n",
    "            associations['many_cluster_to_one_bbox'][\"clusters\"].append(associated_rows.tolist())\n",
    "            associations['many_cluster_to_one_bbox'][\"bbox\"].append([c])            \n",
    "\n",
    "    # ONE TO MANY CHECKS\n",
    "    # ------------------\n",
    "    one_to_many = [] \n",
    "    for r in range(matrix.shape[0]): \n",
    "        if r in rows_with_multiple_truths and r not in many_too_many_rows:\n",
    "            associated_cols = np.where(matrix[r] > 0)[0]\n",
    "            associations['one_cluster_to_many_bbox'][\"clusters\"].append([r])\n",
    "            associations['one_cluster_to_many_bbox'][\"bbox\"].append(associated_cols.tolist())\n",
    "\n",
    "    # ONE TO ONE CHECKS\n",
    "    # ------------------\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(len(matrix[0])):\n",
    "            if matrix[i,j] == 1:\n",
    "                row_sum = sum(matrix[i,:])\n",
    "                col_sum = sum(matrix[:,j]) \n",
    "\n",
    "                if row_sum == 1 and col_sum == 1:\n",
    "                    associations['one_cluster_to_one_bbox']['assigned'].append([i, j]) \n",
    "\n",
    "    if datatype == 'clusters':\n",
    "        associations[\"unassigned_bbox\"][\"bbox\"].extend(list(np.where(np.sum(matrix, axis=0) == 0)[0]))\n",
    "    elif datatype == 'noise':\n",
    "        associations[\"unassigned_bbox\"][\"bbox\"].extend(box for box in list(np.where(np.sum(matrix, axis=0) == 0)[0]) if box in association_list['non_associated_bbox']) \n",
    "\n",
    "    return associations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Association: One to One @Image Plane__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_to_one_association(filtered_cases, association_list):\n",
    "    association_list[\"associated\"].extend(filtered_cases['one_cluster_to_one_bbox']['assigned']) \n",
    "    association_list[\"non_associated_bbox\"].extend(filtered_cases[\"unassigned_bbox\"][\"bbox\"]) \n",
    "    return association_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Association: One to Many @Ground Plane__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_to_many_association(filtered_cases, clusters_on_ground, image_on_ground, datatype='clusters', association_list=None):\n",
    "\n",
    "    if datatype == 'clusters':\n",
    "        lower_idx = 1\n",
    "    elif datatype == 'noise':\n",
    "        lower_idx = 0\n",
    "    else:\n",
    "        raise KeyError(f\"Unexpected datatype '{datatype}'. Expected 'clusters' or 'noise'.\")\n",
    "\n",
    "    list_of_centroid_indices = filtered_cases['one_cluster_to_many_bbox']['clusters']\n",
    "    list_of_box_indices = filtered_cases['one_cluster_to_many_bbox']['bbox']\n",
    "\n",
    "    for centroid, bboxes in zip(list_of_centroid_indices, list_of_box_indices):\n",
    "        centroid_idx = centroid[0]  # Get the centroid index\n",
    "\n",
    "        # Compute Euclidean distances between the centroid and each bounding box\n",
    "        distances = [get_euclidean_distance(clusters_on_ground[datatype][centroid_idx][lower_idx], image_on_ground[box][1]) for box in bboxes]\n",
    "\n",
    "        # Get the index of the bounding box with the minimum distance\n",
    "        min_bbox_idx = distances.index(min(distances))\n",
    "\n",
    "        # Associate the centroid with the closest bounding box\n",
    "        association_list['associated'].append([centroid_idx, bboxes[min_bbox_idx]])\n",
    "\n",
    "        # Add non-associated bounding boxes to the list\n",
    "        association_list['non_associated_bbox'].extend([bbox for i, bbox in enumerate(bboxes) if i != min_bbox_idx])\n",
    "\n",
    "    return association_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Association: Many to One__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_point_finder(points_list, processed_radar_points_to_ground):\n",
    "    x_list = []\n",
    "    for point in points_list:\n",
    "        x_p = processed_radar_points_to_ground['clusters'][point][1][0]\n",
    "        x_list.append(x_p)\n",
    "    \n",
    "    return x_list.index(min(x_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Association__Many to One/Many__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processer_for_multiple_clusters_case(filtered_cases, clusters_on_ground, mode, datatype='clusters'):\n",
    "    if mode == 'many_to_many':\n",
    "        clusters = filtered_cases['many_cluster_to_many_bbox']['clusters'][0]\n",
    "        \n",
    "    elif mode == 'many_to_one':\n",
    "        clusters = filtered_cases['many_cluster_to_one_bbox']['clusters'][0]\n",
    "\n",
    "    # Initialize proximity matrix\n",
    "    first_matrix = np.zeros((len(clusters), len(clusters)))\n",
    "\n",
    "    # Populate proximity matrix based on velocity proximity\n",
    "    for i, p1 in enumerate(clusters):\n",
    "        p1_data = clusters_on_ground['clusters'][p1] if datatype == 'clusters' else clusters_on_ground['noise'][p1]\n",
    "        for j, p2 in enumerate(clusters):\n",
    "            p2_data = clusters_on_ground['clusters'][p2] if datatype == 'clusters' else clusters_on_ground['noise'][p2]\n",
    "            if abs(p1_data[2][0] - p2_data[2][0]) < 0.75:\n",
    "                first_matrix[i][j] = 1\n",
    "\n",
    "    # Merge candidates based on proximity matrix\n",
    "    candidates = [[clusters[j] for j, val in enumerate(row) if val == 1] for row in first_matrix]\n",
    "    candidates = [list(set(candidate)) for candidate in candidates]  # Remove duplicates\n",
    "    \n",
    "    # Merge clusters based on common elements\n",
    "    def merge_candidates(candidates):\n",
    "        while True:\n",
    "            merged_any = False\n",
    "            for i in range(len(candidates)):\n",
    "                for j in range(i + 1, len(candidates)):\n",
    "                    if set(candidates[i]) & set(candidates[j]):  # Merge if overlap exists\n",
    "                        candidates[i] = list(set(candidates[i]) | set(candidates[j]))\n",
    "                        del candidates[j]\n",
    "                        merged_any = True\n",
    "                        break\n",
    "                if merged_any: break\n",
    "            if not merged_any: break\n",
    "        return candidates\n",
    "\n",
    "    new_candidates = merge_candidates(candidates)\n",
    "\n",
    "    return clusters, new_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def many_to_one_association(filtered_cases, association_list, clusters_on_ground, image_on_ground, datatype='clusters'):\n",
    "    \n",
    "    clusters, new_candidates = data_processer_for_multiple_clusters_case(filtered_cases, clusters_on_ground, mode= 'many_to_one', datatype='clusters' )\n",
    "    pre_boxes_list = filtered_cases['many_cluster_to_one_bbox']['bbox'][0]\n",
    "\n",
    "    global_merged_any = any(len(c) > 1 for c in new_candidates)\n",
    "    box_bottom_center = image_on_ground[pre_boxes_list[0]][1]\n",
    "\n",
    "    if not global_merged_any:\n",
    "        # Handle non-merged clusters with Euclidean distance\n",
    "        distance_data = []\n",
    "        for cluster in clusters:\n",
    "            nearest_data = (clusters_on_ground['clusters'][cluster][1] \n",
    "                            if datatype == 'clusters' \n",
    "                            else clusters_on_ground['noise'][cluster][0])\n",
    "            ec_distance = get_euclidean_distance(nearest_data[0:2], box_bottom_center)\n",
    "            distance_data.append(ec_distance)\n",
    "\n",
    "        # Find the cluster with the minimum distance\n",
    "        index_of_chosen_centroid = clusters[distance_data.index(min(distance_data))]\n",
    "        if [index_of_chosen_centroid, pre_boxes_list[0]] not in association_list['associated']:\n",
    "            association_list['associated'].append([index_of_chosen_centroid, pre_boxes_list[0]])\n",
    "\n",
    "    elif len(new_candidates) == 1:\n",
    "            association_list['associated'].append([new_candidates[0], pre_boxes_list[0]])\n",
    "    else:\n",
    "        # handling for partially merged\n",
    "\n",
    "        #This section removes the items which are not clustered\n",
    "        for pair in new_candidates[:]:\n",
    "            if len(pair) < 2:\n",
    "                new_candidates.remove(pair)   \n",
    "\n",
    "        distance_comparison = []\n",
    "        for item in new_candidates:\n",
    "            nearest_point = nearest_point_finder(item, clusters_on_ground)\n",
    "            nearest_point_data = (clusters_on_ground['clusters'][item[nearest_point]][1] \n",
    "                                if datatype == 'clusters' \n",
    "                                else clusters_on_ground['noise'][item[nearest_point]][0])\n",
    "            e_c_distance = get_euclidean_distance(nearest_point_data[0:2], box_bottom_center)\n",
    "            distance_comparison.append(e_c_distance)\n",
    "        \n",
    "        # Handle multiple candidates and select the closest one\n",
    "        final_cluster_to_associate = distance_comparison.index(min(distance_comparison))\n",
    "        index_of_chosen_centroid = new_candidates[final_cluster_to_associate]\n",
    "        if [index_of_chosen_centroid, pre_boxes_list[0]] not in association_list['associated']:\n",
    "            association_list['associated'].append([index_of_chosen_centroid, pre_boxes_list[0]])\n",
    "    \n",
    "    # Handle non-associated boxes\n",
    "    associated_boxes = set(item[1] for item in association_list['associated'])\n",
    "    non_associated_boxes = [box for box in pre_boxes_list if box not in associated_boxes]\n",
    "    association_list['non_associated_bbox'].extend(non_associated_boxes)\n",
    "\n",
    "    return association_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def many_to_many_association(filtered_cases, association_list, clusters_on_ground, image_on_ground, datatype='clusters'):\n",
    "    clusters, new_candidates = data_processer_for_multiple_clusters_case(filtered_cases, clusters_on_ground, mode= 'many_to_many', datatype='clusters' )\n",
    "    pre_boxes_list = filtered_cases['many_cluster_to_many_bbox']['bbox'][0]\n",
    "    box_bottom_centers = np.array([image_on_ground[box][1][:2] for box in pre_boxes_list])\n",
    "    \n",
    "    global_merged_any = any(len(c) > 1 for c in new_candidates)\n",
    "    if not global_merged_any:\n",
    "        \n",
    "        nearest_points = np.array([clusters_on_ground['clusters'][cluster][1][:2] for cluster in clusters])\n",
    "\n",
    "        # Compute distances in a vectorized manner\n",
    "        distance_matrix = np.linalg.norm(nearest_points[:, np.newaxis] - box_bottom_centers[np.newaxis, :], axis=2)\n",
    "\n",
    "        # Find associations where the distance is below the threshold\n",
    "        combined_indices = [(i, np.argmin(distance_matrix[i])) for i in range(distance_matrix.shape[0])\n",
    "                            if np.min(distance_matrix[i]) < 2]\n",
    "        association_list['associated'].extend([(clusters[i], pre_boxes_list[j]) for i, j in combined_indices])\n",
    "\n",
    "    # Merging case: calculate distance using merged candidates\n",
    "    else:\n",
    "        nearest_points = []\n",
    "        for merged in new_candidates:\n",
    "            if len(merged) > 1:\n",
    "                nearest_point_index = nearest_point_finder(merged, clusters_on_ground)\n",
    "                nearest_points.append(clusters_on_ground['clusters'][merged[nearest_point_index]][1][:2])\n",
    "            else:\n",
    "                nearest_points.append(clusters_on_ground['clusters'][merged[0]][1][:2])\n",
    "\n",
    "        nearest_points = np.array(nearest_points)\n",
    "\n",
    "        # Compute distances in a vectorized manner for merged candidates\n",
    "        distance_matrix = np.linalg.norm(nearest_points[:, np.newaxis] - box_bottom_centers[np.newaxis, :], axis=2)\n",
    "\n",
    "        # Find associations where the distance is below the threshold\n",
    "        combined_indices = [(i, np.argmin(distance_matrix[i])) for i in range(distance_matrix.shape[0])\n",
    "                            if np.min(distance_matrix[i]) < 2]\n",
    "        association_list['associated'].extend([(new_candidates[i], pre_boxes_list[j]) for i, j in combined_indices])\n",
    "\n",
    "       # Handle non-associated boxes\n",
    "    associated_boxes = set(item[1] for item in association_list['associated'])\n",
    "    non_associated_boxes = [box for box in pre_boxes_list if box not in associated_boxes]\n",
    "    association_list['non_associated_bbox'].extend(non_associated_boxes)\n",
    "\n",
    "    return association_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Association Visualization @Image Plane__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_drawings(draw, corner_1, corner_2, color, thickness=3, dash_length=10):\n",
    "    # Draw a dashed rectangle\n",
    "    for i in range(corner_1[0], corner_2[0], dash_length * 2):\n",
    "        for t in range(thickness):\n",
    "            draw.line([(i, corner_1[1] + t), (i + dash_length, corner_1[1] + t)], fill=color)\n",
    "\n",
    "            draw.line([(i, corner_2[1] + t), (i + dash_length, corner_2[1] + t)], fill=color)\n",
    "\n",
    "    for i in range(corner_1[1], corner_2[1], dash_length * 2):\n",
    "        for t in range(thickness):\n",
    "            draw.line([(corner_1[0] + t, i), (corner_1[0] + t, i + dash_length)], fill=color)\n",
    "\n",
    "            draw.line([(corner_2[0] + t, i), (corner_2[0] + t, i + dash_length)], fill=color)\n",
    "\n",
    "\n",
    "def get_drawings(colour_idx, image, box_data, centroid_data, datatype='clusters'):\n",
    "    colors = [\n",
    "        (255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0),\n",
    "        (255, 0, 255), (0, 255, 255), (128, 0, 0), (0, 128, 0),\n",
    "        (0, 0, 128), (128, 128, 0)\n",
    "    ]\n",
    "\n",
    "    # Draw original bounding box\n",
    "    original_box = list(map(int, box_data[1:5]))\n",
    "    corner_1, corner_2 = (original_box[0], original_box[1]), (original_box[2], original_box[3])\n",
    "    color = colors[colour_idx]\n",
    "    cv2.rectangle(image, corner_1, corner_2, color, 3)\n",
    "\n",
    "    # Expand the bounding box\n",
    "    expanded_box = list(map(int, expand_bbox(box_data[1:5], scale=1.2)))\n",
    "    exp_corner_1, exp_corner_2 = (expanded_box[0], expanded_box[1]), (expanded_box[2], expanded_box[3])\n",
    "\n",
    "    # Convert to PIL to draw dashed rectangle\n",
    "    img_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    draw = ImageDraw.Draw(img_pil)\n",
    "    draw_dashed_rectangle(draw, exp_corner_1, exp_corner_2, color[::-1])  # RGB to BGR\n",
    "\n",
    "    # Convert back to OpenCV\n",
    "    image = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Draw centroid based on datatype\n",
    "    if datatype == 'clusters':\n",
    "        centroid_point = tuple(map(int, centroid_data[:2]))\n",
    "        cv2.circle(image, centroid_point, 15, color, -1)  # Filled circle for clusters\n",
    "\n",
    "    elif datatype == 'noise':\n",
    "        centroid_point_1 = tuple(map(int, [centroid_data[0] - 12, centroid_data[1] - 12]))\n",
    "        centroid_point_2 = tuple(map(int, [centroid_data[0] + 12, centroid_data[1] + 12]))\n",
    "        cv2.rectangle(image, centroid_point_1, centroid_point_2, color, 3)\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_association(associated_points, box_data, clusters_on_image, image, datatype, colour_idx):\n",
    "    for associated_point in associated_points:\n",
    "        if isinstance(associated_point[0], int):\n",
    "            centroid_data = clusters_on_image[datatype][associated_point[0]][0]\n",
    "            image = get_drawings(colour_idx, image, box_data, centroid_data, datatype)\n",
    "        elif isinstance(associated_point[0], list):\n",
    "            for point in associated_point[0]:\n",
    "                centroid_data = clusters_on_image[datatype][point][0]\n",
    "                image = get_drawings(colour_idx, image, box_data, centroid_data, datatype)\n",
    "    return image, colour_idx + 1\n",
    "\n",
    "\n",
    "def get_image_visualization(final_association_dict, list_of_pred_boxes, clusters_on_image, img_path):\n",
    "\n",
    "    # Load the image\n",
    "    image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    colour_idx = 0\n",
    "\n",
    "    # Handle cluster associations\n",
    "    if final_association_dict.get('with_cluster'):\n",
    "        for associated_point in final_association_dict['with_cluster']:\n",
    "            box_data = list_of_pred_boxes[associated_point[1]]\n",
    "            image, colour_idx = handle_association([associated_point], box_data, clusters_on_image, image, datatype='clusters', colour_idx=colour_idx)\n",
    "\n",
    "    # Handle noise associations\n",
    "    if final_association_dict.get('with_noise'):\n",
    "        for associated_point in final_association_dict['with_noise']:\n",
    "            box_data = list_of_pred_boxes[associated_point[1]]\n",
    "            image, colour_idx = handle_association([associated_point], box_data, clusters_on_image, image, datatype='noise', colour_idx=colour_idx)\n",
    "\n",
    "    # Handle unassigned bounding boxes\n",
    "    if final_association_dict.get('unassigned_bbox'):\n",
    "        for non_associated_point in final_association_dict['unassigned_bbox']:\n",
    "            box_data = list_of_pred_boxes[non_associated_point]\n",
    "            image = get_drawings(colour_idx, image, box_data, None, datatype='unassigned')\n",
    "            colour_idx += 1\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Inference__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_scene(scene_image, scene_pcd, calibration_file):\n",
    "    sensor_calibration_dict = get_sensor_calibration_dict(calibration_file)\n",
    "\n",
    "    for idx, (img, pcd) in enumerate(zip(scene_image, scene_pcd)):\n",
    "        print(f\"Processing Scene {idx}...\")\n",
    "\n",
    "        # YOLO prediction\n",
    "        results = yolo_model.predict(img)\n",
    "        list_of_pred_boxes = class_box_generator_for_pred(results)\n",
    "        pprint(list_of_pred_boxes)\n",
    "\n",
    "        # Cluster Formation\n",
    "        clusters_on_radar = my_custom_dbscan(eps1=0.1, eps2=0.250, min_samples=2).process_pcd_files(pcd)\n",
    "        pprint(clusters_on_radar)\n",
    "\n",
    "        # Project bounding boxes to the ground plane\n",
    "        image_on_ground = []\n",
    "        for result in list_of_pred_boxes:\n",
    "            cls, bbox = result[0], list(result[1:5])\n",
    "            bottom_center_point = [(bbox[2] + bbox[0]) / 2, bbox[3]]\n",
    "            image_point_on_ground = homography(bottom_center_point, sensor_calibration_dict)\n",
    "            image_on_ground.append([[cls], list(image_point_on_ground)])\n",
    "\n",
    "        # Radar dictionaries on different planes\n",
    "        clusters_on_ground = radar_to_ground(clusters_on_radar, sensor_calibration_dict)\n",
    "        clusters_on_image = radar_to_camera(clusters_on_radar, sensor_calibration_dict)\n",
    "\n",
    "        # Association matrices\n",
    "        association_matrix = get_association_matrix(list_of_pred_boxes, clusters_on_image, datatype='clusters')\n",
    "        association_list = {\"associated\": [], \"non_associated_bbox\": []}\n",
    "        print(association_matrix)\n",
    "\n",
    "        if association_matrix is not None:\n",
    "            filtered_cases = get_filtered_cases(association_matrix, datatype='clusters')\n",
    "            print(filtered_cases)\n",
    "\n",
    "            # Association steps\n",
    "            if filtered_cases:  # Check if there are filtered cases\n",
    "\n",
    "                if filtered_cases:\n",
    "                    association_list = get_one_to_one_association(filtered_cases, association_list)\n",
    "\n",
    "                if len(filtered_cases['one_cluster_to_many_bbox']['clusters']):\n",
    "                    association_list = get_one_to_many_association(\n",
    "                        filtered_cases, clusters_on_ground, image_on_ground, association_list=association_list, datatype='clusters')\n",
    "                \n",
    "                if len(filtered_cases['many_cluster_to_one_bbox']['clusters']) > 0:\n",
    "                    association_list = many_to_one_association(filtered_cases, association_list, clusters_on_ground, image_on_ground, datatype='clusters')\n",
    "     \n",
    "                if len(filtered_cases['many_cluster_to_many_bbox']['clusters']):\n",
    "                    association_list = many_to_many_association(filtered_cases, association_list, clusters_on_ground, image_on_ground, datatype='clusters')\n",
    "\n",
    "\n",
    "        # Final associations\n",
    "        print(f'association_list: {association_list}')\n",
    "        final_association_dict = {\n",
    "            'with_cluster': association_list['associated'],\n",
    "            # 'with_noise': noise_association_list['associated'],\n",
    "            # 'unassigned_bbox': noise_association_list['non_associated_bbox']\n",
    "        }\n",
    "\n",
    "        print(final_association_dict)\n",
    "        # Uncomment the following lines to visualize the results\n",
    "        # final_image = get_image_visualization(final_association_dict, list_of_pred_boxes, clusters_on_image, img)\n",
    "        # cv2.imshow('Image Window', final_image)\n",
    "        # cv2.waitKey(0)\n",
    "    \n",
    "    # cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Scene 0...\n",
      "\n",
      "image 1/1 C:\\Users\\hussa\\OneDrive\\Desktop\\Projects\\Project\\MOT\\INFRA-3DRC_scene-22\\INFRA-3DRC_scene-22\\camera_01\\camera_01__data\\camera_01__2023-06-02-22-32-29-989.png: 416x640 1 bus, 2880.6ms\n",
      "Speed: 4.5ms preprocess, 2880.6ms inference, 2.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "array([[          4,           0,      193.74,       666.5,      670.41,     0.94762]], dtype=float32)\n",
      "{'clusters': [[[13.745777130126953, 5.611412048339844, -0.5118474960327148],\n",
      "               [6.67625093460083, 5.611412048339844, -0.6593458652496338],\n",
      "               [-9.468095779418945]],\n",
      "              [[14.996161460876465, 14.07302188873291, -0.8995653986930847],\n",
      "               [13.802179336547852, 14.07302188873291, -0.02230207808315754],\n",
      "               [-0.23880572617053986]],\n",
      "              [[18.8121395111084, 12.777000427246094, 0.8344192504882812],\n",
      "               [18.167457580566406, 12.777000427246094, 0.7909148335456848],\n",
      "               [0.1470252424478531]],\n",
      "              [[25.09867286682129, 9.72446346282959, 0.9877328872680664],\n",
      "               [24.6921443939209, 9.72446346282959, 1.3843460083007812],\n",
      "               [-0.6470837593078613]],\n",
      "              [[34.92659378051758, 18.121658325195312, -3.1234498023986816],\n",
      "               [33.23134231567383, 18.121658325195312, -2.5542309284210205],\n",
      "               [0.09919088333845139]],\n",
      "              [[39.87343215942383, 15.357277870178223, 0.9393250346183777],\n",
      "               [39.05675506591797, 15.357277870178223, -3.033935785293579],\n",
      "               [0.16271120309829712]],\n",
      "              [[35.77280807495117, 24.942113876342773, -4.3203253746032715],\n",
      "               [35.84955978393555, 24.942113876342773, -5.193906307220459],\n",
      "               [0.3270399570465088]]],\n",
      " 'noise': [[[7.076074600219727, -4.283449649810791, -2.1596412658691406],\n",
      "            [-0.11997126787900925]],\n",
      "           [[21.205562591552734, 4.842031478881836, -2.3071305751800537],\n",
      "            [-0.10142789036035538]],\n",
      "           [[20.171630859375, 16.030052185058594, 0.5339775085449219],\n",
      "            [-0.3770236670970917]],\n",
      "           [[36.46547317504883, -4.255484580993652, 4.7122802734375],\n",
      "            [-0.17504648864269257]],\n",
      "           [[37.50245666503906, -4.671449184417725, 6.072448253631592],\n",
      "            [-0.12401751428842545]],\n",
      "           [[38.33523941040039, -18.619918823242188, -7.228606700897217],\n",
      "            [1.0158915519714355]],\n",
      "           [[45.58381271362305, 12.422775268554688, -4.087111473083496],\n",
      "            [0.1819019913673401]]]}\n",
      "[[          1]\n",
      " [          0]\n",
      " [          0]\n",
      " [          1]\n",
      " [          1]\n",
      " [          1]\n",
      " [          0]]\n",
      "{'many_cluster_to_many_bbox': {'clusters': [], 'bbox': []}, 'many_cluster_to_one_bbox': {'clusters': [[0, 3, 4, 5]], 'bbox': [[0]]}, 'one_cluster_to_many_bbox': {'clusters': [], 'bbox': []}, 'one_cluster_to_one_bbox': {'assigned': []}, 'unassigned_bbox': {'bbox': []}}\n",
      "association_list: {'associated': [], 'non_associated_bbox': []}\n",
      "association_list: {'associated': [[[3, 4, 5], 0]], 'non_associated_bbox': []}\n",
      "{'with_cluster': [[[3, 4, 5], 0]]}\n"
     ]
    }
   ],
   "source": [
    "process_scene(scene_image, scene_pcd, calibration_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Final Association List\\n    final_association_dict = {'with_cluster': [], 'with_noise': [], 'unassigned_bbox': []}\\n    final_association_dict['with_cluster'].extend(association_list['associated'])\\n    final_association_dict['with_noise'].extend(noise_association_list['associated'])\\n    final_association_dict['unassigned_bbox'].extend(noise_association_list['non_associated_bbox'])\\n    \\n    if my_image and my_plot:\\n        my_image.clear()\\n        my_plot.clear()\\n\\n    # Plot Ground Plane Points\\n    camera_plotting(image_on_ground, my_plot)\\n    radar_plotting(clusters_on_ground, my_plot)\\n\\n    # Visualize Association on Image Plane\\n    image_visualize = get_image_visualization(final_association_dict, list_of_pred_boxes, clusters_on_image, img)\\n\\n    # Convert BGR to RGB for displaying with Matplotlib\\n    image_rgb = cv2.cvtColor(image_visualize, cv2.COLOR_BGR2RGB)\\n\\n    # Update the image display\\n    my_image.imshow(image_rgb)\\n    my_image.set_title('Image')\\n\\n    # Refresh the canvas\\n    fig.canvas.draw()\\n    fig.canvas.flush_events()\\n\\n    # Small pause to allow for real-time interaction without freezing\\n    plt.pause(0.001)\\n\\n    # Disable interactive mode after the visualization is complete\\n    plt.ioff()\\n\\n\""
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Final Association List\n",
    "    final_association_dict = {'with_cluster': [], 'with_noise': [], 'unassigned_bbox': []}\n",
    "    final_association_dict['with_cluster'].extend(association_list['associated'])\n",
    "    final_association_dict['with_noise'].extend(noise_association_list['associated'])\n",
    "    final_association_dict['unassigned_bbox'].extend(noise_association_list['non_associated_bbox'])\n",
    "    \n",
    "    if my_image and my_plot:\n",
    "        my_image.clear()\n",
    "        my_plot.clear()\n",
    "\n",
    "    # Plot Ground Plane Points\n",
    "    camera_plotting(image_on_ground, my_plot)\n",
    "    radar_plotting(clusters_on_ground, my_plot)\n",
    "\n",
    "    # Visualize Association on Image Plane\n",
    "    image_visualize = get_image_visualization(final_association_dict, list_of_pred_boxes, clusters_on_image, img)\n",
    "\n",
    "    # Convert BGR to RGB for displaying with Matplotlib\n",
    "    image_rgb = cv2.cvtColor(image_visualize, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Update the image display\n",
    "    my_image.imshow(image_rgb)\n",
    "    my_image.set_title('Image')\n",
    "\n",
    "    # Refresh the canvas\n",
    "    fig.canvas.draw()\n",
    "    fig.canvas.flush_events()\n",
    "\n",
    "    # Small pause to allow for real-time interaction without freezing\n",
    "    plt.pause(0.001)\n",
    "\n",
    "    # Disable interactive mode after the visualization is complete\n",
    "    plt.ioff()\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
